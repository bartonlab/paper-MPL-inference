{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation of test data for performance tests\n",
    "\n",
    "This notebook records the parameters for Wright-Fisher simulations used to generate our test data sets, as well as commands for running inference algorithms on the test data and compiling the results. In this work we have considered **four** scenarios intended to explore different regimes of computational and evolutionary complexity:\n",
    "\n",
    "1. small simple\n",
    "2. medium simple\n",
    "3. small complex\n",
    "4. medium complex\n",
    "\n",
    "Parameters for each of these scenarios are given below in **Section 1**.\n",
    "\n",
    "We analyzed the resulting trajectories with **XX** different algorithms:\n",
    "\n",
    "1. **Marginal Path Likelihood (MPL)** [[code](https://github.com/bartonlab/MPL)] [paper] \n",
    "2. **MPL without mutation**\n",
    "3. **Single Locus (SL)** (MPL without covariance)\n",
    "4. **SL without mutation**\n",
    "5. CLEAR [[code](https://github.com/airanmehr/CLEAR)] [[paper](http://www.genetics.org/content/206/2/1011)]\n",
    "6. EandR-timeseries [[code](https://github.com/terhorst/EandR-timeseries)] [[paper](http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1005069)]\n",
    "7. poolSeq [[code](https://github.com/ThomasTaus/poolSeq)] [[paper](https://academic.oup.com/mbe/article/doi/10.1093/molbev/msx225/4086114)]\n",
    "8. ...\n",
    "9. ...\n",
    "10. ...\n",
    "\n",
    "Methods in **bold** are described in the present work. For other methods we have included a link to the code repository (if available) and to the corresponding paper. Scripts to run and compile output from each of these methods are collected in **Section 2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was prepared using:\n",
      "python version 3.6.3 (default, Oct  4 2017, 06:09:15) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)]\n",
      "numpy version 1.13.3\n",
      "pandas version 0.21.0\n",
      "scikit-learn version 0.19.1\n"
     ]
    }
   ],
   "source": [
    "# Full library list and version numbers\n",
    "\n",
    "print('This notebook was prepared using:')\n",
    "\n",
    "import sys\n",
    "print('python version %s' % sys.version)\n",
    "\n",
    "import numpy as np\n",
    "print('numpy version %s' % np.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "print('pandas version %s' % pd.__version__)\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('scikit-learn version %s' % sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Generation of test data through Wright-Fisher simulations\n",
    "\n",
    "Wright-Fisher simulations are performed using `wfsim/Wright-Fisher.py`. The output of these simulations is saved for processing. The code below creates multiple job files for running many simulations in parallel on a computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "TESTS   = [   'small_simple',      'medium_simple',      'small_complex',    'medium_complex']\n",
    "N_VALS  = dict(small_simple=  1000, medium_simple=  1000, small_complex=1000, medium_complex=1000)\n",
    "L_VALS  = dict(small_simple=    10, medium_simple=    50, small_complex=  10, medium_complex=  50)\n",
    "T0_VALS = dict(small_simple=     0, medium_simple=     0, small_complex=  10, medium_complex=  10)\n",
    "T_VALS  = dict(small_simple=   150, medium_simple=  1000, small_complex=  70, medium_complex= 310)\n",
    "MU_VALS = dict(small_simple=  5e-4, medium_simple=  1e-4, small_complex=5e-4, medium_complex=1e-4)\n",
    "NB_VALS = dict(small_simple=     4, medium_simple=    10, small_complex=   4, medium_complex=  10)\n",
    "ND_VALS = dict(small_simple=     4, medium_simple=    10, small_complex=   4, medium_complex=  10)\n",
    "SB_VALS = dict(small_simple= 0.025, medium_simple= 0.025, small_complex= 0.1, medium_complex= 0.1)\n",
    "SD_VALS = dict(small_simple=-0.025, medium_simple=-0.025, small_complex=-0.1, medium_complex=-0.1)\n",
    "\n",
    "N_TRIALS     = 100   # number of independent trials to run for each test set\n",
    "COMP_NS_VALS = [100] # number of sequence samples to collect per time point \n",
    "COMP_DT_VALS = [ 10] # time between sampling events (in discrete generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbs_str = \"\"\"#!/bin/bash\\n#PBS -m abe\\n#PBS -M jpbarton\\n#PBS -k oe\\n#PBS -j oe\\n#PBS -l nodes=1:ppn=1\\n\"\"\"\n",
    "\n",
    "# SMALL SIMPLE, 100x runs of\n",
    "# \n",
    "#     N   = 10^3         (population size)\n",
    "#     T   = 10^4         (total number of generations to simulate)\n",
    "#     mu  = 5 x 10^{-4}  (mutation rate)\n",
    "#     L   = 10           (sequence length) \n",
    "#     n_b = 4            (number of beneficial mutations)\n",
    "#     n_d = 4            (number of deleterious mutations)\n",
    "#     s_b =  0.025       (selection coefficient for beneficial mutations)\n",
    "#     s_d = -0.025       (selection coefficient for deleterious mutations)\n",
    "\n",
    "test     = 'small_simple'\n",
    "job_pars = {'-T'   : int(1.0e4),\n",
    "            '-N'   : N_VALS[test],\n",
    "            '-L'   : L_VALS[test],\n",
    "            '--mu' : MU_VALS[test],\n",
    "            '--nB' : NB_VALS[test],\n",
    "            '--fB' : SB_VALS[test],\n",
    "            '--nD' : ND_VALS[test],\n",
    "            '--fD' : SD_VALS[test] }\n",
    "job_sub = open('wfsim/jobs/run_wfsim_'+test+'.sh', 'w')\n",
    "for t in range(N_TRIALS):\n",
    "    trial_str = 'wfsim_'+test+'_%d' % t\n",
    "    job_sub.write('qsub -q verylong %s > /dev/null\\n' % ('wfsim/jobs/'+trial_str+'.pbs'))\n",
    "    with open('wfsim/jobs/'+trial_str+'.pbs', 'w') as f:\n",
    "        f.write(pbs_str)\n",
    "        f.write('python wfsim/Wright-Fisher.py -o wfsim/data/%s ' % trial_str)\n",
    "        f.write('%s\\n' % (' '.join([k + ' ' + str(v) for k, v in job_pars.items()])))\n",
    "job_sub.close()\n",
    "\n",
    "\n",
    "# MEDIUM SIMPLE, 100x runs of\n",
    "# \n",
    "#     N   = 10^3         (population size)\n",
    "#     T   = 10^4         (total number of generations to simulate)\n",
    "#     mu  = 1 x 10^{-4}  (mutation rate)\n",
    "#     L   = 50           (sequence length) \n",
    "#     n_b = 10           (number of beneficial mutations)\n",
    "#     n_d = 10           (number of deleterious mutations)\n",
    "#     s_b =  0.025       (selection coefficient for beneficial mutations)\n",
    "#     s_d = -0.025       (selection coefficient for deleterious mutations)\n",
    "\n",
    "test     = 'medium_simple'\n",
    "job_pars = {'-T'   : int(1.0e4),\n",
    "            '-N'   : N_VALS[test],\n",
    "            '-L'   : L_VALS[test],\n",
    "            '--mu' : MU_VALS[test],\n",
    "            '--nB' : NB_VALS[test],\n",
    "            '--fB' : SB_VALS[test],\n",
    "            '--nD' : ND_VALS[test],\n",
    "            '--fD' : SD_VALS[test] }\n",
    "job_sub = open('wfsim/jobs/run_wfsim_'+test+'.sh', 'w')\n",
    "for t in range(N_TRIALS):\n",
    "    trial_str = 'wfsim_'+test+'_%d' % t\n",
    "    job_sub.write('qsub -q verylong %s > /dev/null\\n' % ('wfsim/jobs/'+trial_str+'.pbs'))\n",
    "    with open('wfsim/jobs/'+trial_str+'.pbs', 'w') as f:\n",
    "        f.write(pbs_str)\n",
    "        f.write('python wfsim/Wright-Fisher.py -o wfsim/data/%s ' % trial_str)\n",
    "        f.write('%s\\n' % (' '.join([k + ' ' + str(v) for k, v in job_pars.items()])))\n",
    "job_sub.close()\n",
    "\n",
    "\n",
    "# SMALL COMPLEX, 100x runs of\n",
    "# \n",
    "#     N   = 10^3         (population size)\n",
    "#     T   = 10^4         (total number of generations to simulate)\n",
    "#     mu  = 5 x 10^{-4}  (mutation rate)\n",
    "#     L   = 10           (sequence length) \n",
    "#     n_b = 4            (number of beneficial mutations)\n",
    "#     n_d = 4            (number of deleterious mutations)\n",
    "#     s_b =  0.100       (selection coefficient for beneficial mutations)\n",
    "#     s_d = -0.100       (selection coefficient for deleterious mutations)\n",
    "#\n",
    "# For these simulations the starting population is evenly split between\n",
    "# 3 collections of sequences with randomly chosen mutations (probability\n",
    "# of mutation is 50% at each site independent of other sites, \n",
    "# see Wright-Fisher.py for details)\n",
    "\n",
    "test     = 'small_complex'\n",
    "job_pars = {'-T'   : int(1.0e4),\n",
    "            '-N'   : N_VALS[test],\n",
    "            '-L'   : L_VALS[test],\n",
    "            '--mu' : MU_VALS[test],\n",
    "            '--nB' : NB_VALS[test],\n",
    "            '--fB' : SB_VALS[test],\n",
    "            '--nD' : ND_VALS[test],\n",
    "            '--fD' : SD_VALS[test],\n",
    "             '--random' : 3 }\n",
    "job_sub   = open('wfsim/jobs/run_wfsim_'+test+'.sh', 'w')\n",
    "for t in range(N_TRIALS):\n",
    "    trial_str = 'wfsim_'+test+'_%d' % t\n",
    "    job_sub.write('qsub -q verylong %s > /dev/null\\n' % ('wfsim/jobs/'+trial_str+'.pbs'))\n",
    "    with open('wfsim/jobs/'+trial_str+'.pbs', 'w') as f:\n",
    "        f.write(pbs_str)\n",
    "        f.write('python wfsim/Wright-Fisher.py -o wfsim/data/%s ' % trial_str)\n",
    "        f.write('%s\\n' % (' '.join([k + ' ' + str(v) for k, v in job_pars.items()])))\n",
    "job_sub.close()\n",
    "\n",
    "\n",
    "# MEDIUM COMPLEX, 100x runs of\n",
    "# \n",
    "#     N   = 10^3         (population size)\n",
    "#     T   = 10^4         (total number of generations to simulate)\n",
    "#     mu  = 1 x 10^{-4}  (mutation rate)\n",
    "#     L   = 50           (sequence length) \n",
    "#     n_b = 10           (number of beneficial mutations)\n",
    "#     n_d = 10           (number of deleterious mutations)\n",
    "#     s_b =  0.100       (selection coefficient for beneficial mutations)\n",
    "#     s_d = -0.100       (selection coefficient for deleterious mutations)\n",
    "#\n",
    "# For these simulations the starting population is evenly split between\n",
    "# 5 collections of sequences with randomly chosen mutations (probability\n",
    "# of mutation is 50% at each site independent of other sites, \n",
    "# see Wright-Fisher.py for details)\n",
    "\n",
    "test     = 'medium_complex'\n",
    "job_pars = {'-T'   : int(1.0e4),\n",
    "            '-N'   : N_VALS[test],\n",
    "            '-L'   : L_VALS[test],\n",
    "            '--mu' : MU_VALS[test],\n",
    "            '--nB' : NB_VALS[test],\n",
    "            '--fB' : SB_VALS[test],\n",
    "            '--nD' : ND_VALS[test],\n",
    "            '--fD' : SD_VALS[test],\n",
    "            '--random' : 5 }\n",
    "job_sub   = open('wfsim/jobs/run_wfsim_'+test+'.sh', 'w')\n",
    "for t in range(N_TRIALS):\n",
    "    trial_str = 'wfsim_'+test+'_%d' % t\n",
    "    job_sub.write('qsub -q verylong %s > /dev/null\\n' % ('wfsim/jobs/'+trial_str+'.pbs'))\n",
    "    with open('wfsim/jobs/'+trial_str+'.pbs', 'w') as f:\n",
    "        f.write(pbs_str)\n",
    "        f.write('python wfsim/Wright-Fisher.py -o wfsim/data/%s ' % trial_str)\n",
    "        f.write('%s\\n' % (' '.join([k + ' ' + str(v) for k, v in job_pars.items()])))\n",
    "job_sub.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Wright-Fisher trajectories have been generated, we subsample them to create our test trajectories using `wfsim/py2c.py`. For comparison between inference methods we chose to take 100 sequences per sample, with samples taken every 10 generations. The starting and ending generations of these test trajectories are\n",
    "\n",
    "1. small simple -- start 0, end 150\n",
    "2. medium simple -- start 0, end 1000\n",
    "3. small complex -- start 10, end 70\n",
    "4. medium complex -- start 10, end 310\n",
    "\n",
    "The code below produces four shell scripts `expand_small_simple.sh`, `expand_medium_simple.sh`, `expand_small_complex.sh`, and `expand_medium_complex.sh`, which can be run to extract the trajectories from the compressed output of `wfsim/Wright-Fisher.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sub-trajectories from full samples\n",
    "\n",
    "for t in TESTS:\n",
    "    job_sub = open('expand_%s.sh' % t, 'w')\n",
    "    for ns in COMP_NS_VALS:\n",
    "        for dt in COMP_DT_VALS:\n",
    "            for i in range(N_TRIALS):\n",
    "                job_sub.write('python3 wfsim/py2c.py -i wfsim/data/wfsim_%s_%d -t %d -T %d --ns %d --dt %d -s %d\\n' \n",
    "                            % (t, i, T0_VALS[t], T_VALS[t], ns, dt, i))\n",
    "    job_sub.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Running the inference algorithms and compiling output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. MPL, MPL without mutation, SL, SL without mutation\n",
    "\n",
    "First create the job files and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbs_str = \"\"\"#!/bin/bash\\n#PBS -m abe\\n#PBS -M jpbarton\\n#PBS -k oe\\n#PBS -j oe\\n#PBS -l nodes=1:ppn=1\\n\"\"\"\n",
    "\n",
    "ns_vals = [10, 20, 30, 40, 50,  80, 100, 1000]\n",
    "dt_vals = [ 1,  5, 10, 20, 50, 100, 200,  250]\n",
    "\n",
    "for t in TESTS:\n",
    "    job_sub = open('MPL/jobs/run_wfinf_%s.sh' % t, 'w')\n",
    "    job_sub.write('g++ MPL/src/main.cpp MPL/src/inf.cpp MPL/src/io.cpp -O3 -lgslcblas -lgsl -o mpl\\n')\n",
    "    for ns in ns_vals:\n",
    "        for dt in dt_vals:\n",
    "            trial_str = 'wfinf_%s_T%d_ns%d_dt%d' % (t, T_VALS[t], ns, dt)\n",
    "            job_sub.write('qsub -q verylong %s > /dev/null\\n' % ('MPL/jobs/'+trial_str+'.pbs'))\n",
    "            with open('MPL/jobs/'+trial_str+'.pbs', 'w') as f:\n",
    "                f.write(pbs_str)\n",
    "                for i in range(N_TRIALS):\n",
    "                    i_str = 'wfsim/data/wfsim_%s_%d_T%d_ns%d_dt%d' % (t, i, T_VALS[t], ns, dt)\n",
    "                    o_str = 'MPL/out/%s_%d_T%d_ns%d_dt%d'          % (t, i, T_VALS[t], ns, dt)\n",
    "                    f.write('python wfsim/py2c.py -i wfsim/data/wfsim_%s_%d -t %d -T %d --ns %d --dt %d -s %d\\n' \n",
    "                            % (t, i, T0_VALS[t], T_VALS[t], ns, dt, i))\n",
    "                    f.write('./mpl -i %s.dat -o %s_MPL.dat'            % (i_str, o_str))\n",
    "                    f.write(' -g 1e3 -N %d -mu %.3e > /dev/null\\n'     % (N_VALS[t], MU_VALS[t]))\n",
    "                    f.write('./mpl -i %s.dat -o %s_MPL_noMu.dat'       % (i_str, o_str))\n",
    "                    f.write(' -g 1e3 -N %d -mu 0 > /dev/null\\n'        % (N_VALS[t]))\n",
    "                    f.write('./mpl -i %s.dat -o %s_SL.dat'             % (i_str, o_str))\n",
    "                    f.write(' -nc -g 1e3 -N %d -mu %.3e > /dev/null\\n' % (N_VALS[t], MU_VALS[t]))\n",
    "                    f.write('./mpl -i %s.dat -o %s_SL_noMu.dat'        % (i_str, o_str))\n",
    "                    f.write(' -nc -g 1e3 -N %d -mu 0 > /dev/null\\n'    % (N_VALS[t]))\n",
    "                    f.write('rm %s.dat\\n' % i_str)\n",
    "    job_sub.close()\n",
    "\n",
    "    methods = ['MPL', 'SL', 'MPL_noMu', 'SL_noMu']\n",
    "\n",
    "    job_collect = open('MPL/jobs/run_wfinf_%s_collect.sh' % t, 'w')\n",
    "    job_collect.write('python MPL/collect_s.py -i MPL/out/%s -n %d -T %d -t %d' % (t, N_TRIALS, T_VALS[t], T0_VALS[t]))\n",
    "    for  m in methods: job_collect.write(  ' -m %s' %  m)\n",
    "    for ns in ns_vals: job_collect.write(' --ns %d' % ns)\n",
    "    for dt in dt_vals: job_collect.write(' --dt %d' % dt)\n",
    "    job_collect.write(' &\\n')\n",
    "    job_collect.write('cd MPL/out && tar czf %s.tar.gz ' % (t))\n",
    "    for m in methods: job_collect.write(' *%s*_%s.dat' % (t, m))\n",
    "    job_collect.write(' && cd ../..')\n",
    "    job_collect.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next collect and organize the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TESTS:\n",
    "    true_ben = [1 if i in                       range(NB_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    true_del = [1 if i in  range(L_VALS[t]-ND_VALS[t], L_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    true_neu = [1 if i in range(NB_VALS[t], L_VALS[t]-ND_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    coefs    = ['s%d' % j for j in range(L_VALS[t])]\n",
    "    \n",
    "    df              = pd.read_csv('MPL/out/%s_collected.csv' % (t), memory_map=True)\n",
    "    df['AUROC_ben'] = pd.Series(data=[roc_auc_score(true_ben, np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "    df['AUROC_del'] = pd.Series(data=[roc_auc_score(true_del,-np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "    for i in range(L_VALS[t]):\n",
    "        if   true_ben[i]: df['ds%d' % i] = df['s%d' % i] - SB_VALS[t]\n",
    "        elif true_del[i]: df['ds%d' % i] = df['s%d' % i] - SD_VALS[t]\n",
    "        elif true_neu[i]: df['ds%d' % i] = df['s%d' % i]\n",
    "        \n",
    "    df.to_csv('data/MPL_%s_collected_extended.csv.gz' % (t), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CLEAR\n",
    "\n",
    "First create the job files and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbs_str = \"\"\"#!/bin/bash\\n#PBS -m abe\\n#PBS -M jpbarton\\n#PBS -k oe\\n#PBS -j oe\\n#PBS -l nodes=1:ppn=1\\n\"\"\"\n",
    "pbs_str = pbs_str + 'START=$(date +\"%s.%N\")\\n'\n",
    "pbs_end = 'RUNTIME=$(echo \"$(date +%s.%N) - $START\" | bc)\\necho \"$RUNTIME\" >> '\n",
    "\n",
    "for t in TESTS:\n",
    "    job_sub = open('CLEAR/jobs/run_%s.sh' % t, 'w')\n",
    "    for ns in COMP_NS_VALS:\n",
    "        for dt in COMP_DT_VALS:\n",
    "            for i in range(N_TRIALS):\n",
    "                _data     = np.loadtxt('wfsim/data/wfsim_%s_%d_T%d_ns%d_dt%d.dat' % (t, i, T_VALS[t], ns, dt))\n",
    "                _L        = len(_data[0][2:])\n",
    "                times     = np.unique(_data.T[0])\n",
    "                positions = np.array(range(1, _L+1),int)\n",
    "\n",
    "                levels     = [[1], [int(_t) for _t in times], ['C', 'D']]\n",
    "                names      = ['REP', 'GEN', 'READ']\n",
    "                indices    = ['CHROM', 'POS']\n",
    "                col_values = {}\n",
    "                col_tuples = []\n",
    "                idx_tuples = [('chrI', l+1) for l in range(_L)]\n",
    "\n",
    "                for j in range(len(times)):\n",
    "                    _t_data = np.array([_d[2:] for _d in _data if _d[0]==times[j]])\n",
    "                    _t_num  = np.array([ _d[1] for _d in _data if _d[0]==times[j]])\n",
    "                    _t_sum  = np.einsum('i,ij->j', _t_num, _t_data)\n",
    "                    for l in range(_L):\n",
    "                        col_tuples.append((1, int(times[j]), 'C'))\n",
    "                        col_tuples.append((1, int(times[j]), 'D'))\n",
    "                        if (1, int(times[j]), 'C') in col_values:\n",
    "                            col_values[(1, int(times[j]), 'C')].append(_t_sum[l]+1)\n",
    "                            col_values[(1, int(times[j]), 'D')].append(np.sum(_t_num)+1)\n",
    "                        else:\n",
    "                            col_values[(1, int(times[j]), 'C')] = [_t_sum[l]+1]\n",
    "                            col_values[(1, int(times[j]), 'D')] = [np.sum(_t_num)+1]\n",
    "\n",
    "                df_CLEAR = pd.DataFrame(col_values, index = np.array(range(_L),int)+1)\n",
    "                df_CLEAR.columns.names = tuple(names)\n",
    "                df_CLEAR.to_pickle('CLEAR/data/%s_%d.df' % (t, i))\n",
    "                \n",
    "                o_str = '%s_%d' % (t, i)\n",
    "                with open('CLEAR/jobs/%s.pbs' % (o_str), 'w') as f:\n",
    "                    f.write(pbs_str)\n",
    "                    f.write('python3 CLEAR/CLEAR.py --pandas CLEAR/data/%s.df' % (o_str))\n",
    "                    f.write(' --N %d --out CLEAR/out/%s.df\\n'                  % (N_VALS[t], o_str))\n",
    "                    f.write('%sCLEAR/out/%s_time.dat\\n'                        % (pbs_end, o_str))\n",
    "                \n",
    "                job_sub.write('qsub -q verylong CLEAR/jobs/%s_%d.pbs > /dev/null\\n' % (t, i))\n",
    "                \n",
    "    job_sub.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next collect and organize the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CLEAR results\n",
    "\n",
    "for t in TESTS:\n",
    "    true_ben = [1 if i in                       range(NB_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    true_del = [1 if i in  range(L_VALS[t]-ND_VALS[t], L_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    true_neu = [1 if i in range(NB_VALS[t], L_VALS[t]-ND_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    coefs    = ['s%d' % j for j in range(L_VALS[t])]\n",
    "    \n",
    "    f    = open('CLEAR/out/%s_collected.csv' % (t), 'w')\n",
    "    head = 'trajectory,method,t0,T,ns,deltat,runtime,' + (','.join(coefs))\n",
    "    f.write('%s\\n' % head)\n",
    "    \n",
    "    for n in range(N_TRIALS):\n",
    "        temp_df = pd.melt(pd.read_pickle('CLEAR/out/%s_%d.df' % (t, n)))\n",
    "        temp_s  = np.array(temp_df[temp_df.stat=='s'].value)\n",
    "        temp_t  = float([i.split() for i in open('CLEAR/out/%s_%d_time.dat' % (t, n)).readlines()][-1][0])\n",
    "        \n",
    "        f.write('%d,%s,%d,%d,%d,%d,%lf,' % (n, 'CLEAR', T0_VALS[t], T_VALS[t], ns, dt, temp_t))\n",
    "        f.write(','.join(['%lf' % s for s in temp_s]))\n",
    "        f.write('\\n')\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    df              = pd.read_csv('CLEAR/out/%s_collected.csv' % (t), memory_map=True)\n",
    "    df['AUROC_ben'] = pd.Series(data=[roc_auc_score(true_ben, np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "    df['AUROC_del'] = pd.Series(data=[roc_auc_score(true_del,-np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "    for i in range(L_VALS[t]):\n",
    "        if   true_ben[i]: df['ds%d' % i] = df['s%d' % i] - SB_VALS[t]\n",
    "        elif true_del[i]: df['ds%d' % i] = df['s%d' % i] - SD_VALS[t]\n",
    "        elif true_neu[i]: df['ds%d' % i] = df['s%d' % i]\n",
    "        \n",
    "    df.to_csv('data/CLEAR_%s_collected_extended.csv.gz' % (t), compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. EandR-timeseries\n",
    "\n",
    "First create the job files and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbs_str = \"\"\"#!/bin/bash\\n#PBS -m abe\\n#PBS -M jpbarton\\n#PBS -k oe\\n#PBS -j oe\\n#PBS -l nodes=1:ppn=4\\n\"\"\"\n",
    "pbs_str = pbs_str + 'START=$(date +\"%s.%N\")\\n'\n",
    "pbs_end = 'RUNTIME=$(echo \"$(date +%s.%N) - $START\" | bc)\\necho \"$RUNTIME\" >> '\n",
    "\n",
    "for t in TESTS:\n",
    "    job_sub_ind  = open('EandR/jobs/run_%s_independent.sh' % t, 'w')\n",
    "    job_sub_link = open('EandR/jobs/run_%s_linked.sh'      % t, 'w')\n",
    "    for ns in COMP_NS_VALS:\n",
    "        for dt in COMP_DT_VALS:\n",
    "            for i in range(N_TRIALS):\n",
    "                o_str = 'EandR/out/%s_%d' % (t, i)\n",
    "                i_str = 'wfsim/data/wfsim_%s_%d_T%d_ns%d_dt%d.dat' % (t, i, T_VALS[t], ns, dt)\n",
    "                with open('EandR/jobs/%s_%d_independent.pbs' % (t, i), 'w') as f:\n",
    "                    f.write(pbs_str)\n",
    "                    f.write('python3 EandR/EandR.py -N %d -i %s -o %s_independent.dat\\n' % (N_VALS[t], i_str, o_str))\n",
    "                    f.write('%s%s_independent_time.dat\\n'                                % (pbs_end, o_str))\n",
    "                    job_sub_ind.write('qsub -q verylong EandR/jobs/%s_%d_independent.pbs > /dev/null\\n' % (t, i))\n",
    "                with open('EandR/jobs/%s_%d_linked.pbs' % (t, i), 'w') as f:\n",
    "                    f.write(pbs_str)\n",
    "                    f.write('python3 EandR/EandR.py -N %d -i %s -o %s_linked.dat -l\\n' % (N_VALS[t], i_str, o_str))\n",
    "                    f.write('%s%s_linked_time.dat\\n'                                   % (pbs_end, o_str))\n",
    "                    job_sub_link.write('qsub -q verylong EandR/jobs/%s_%d_linked.pbs > /dev/null\\n' % (t, i))\n",
    "                \n",
    "    job_sub_ind.close()\n",
    "    job_sub_link.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next collect and organize the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in TESTS:\n",
    "    true_ben = [1 if i in                       range(NB_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    true_del = [1 if i in  range(L_VALS[t]-ND_VALS[t], L_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    true_neu = [1 if i in range(NB_VALS[t], L_VALS[t]-ND_VALS[t]) else 0 for i in range(L_VALS[t])]\n",
    "    coefs    = ['s%d' % j for j in range(L_VALS[t])]\n",
    "    \n",
    "    f    = open('EandR/out/%s_collected.csv' % (t), 'w')\n",
    "    head = 'trajectory,method,t0,T,ns,deltat,runtime,' + (','.join(coefs))\n",
    "    f.write('%s\\n' % head)\n",
    "    \n",
    "    for n in range(N_TRIALS):\n",
    "        temp_s = np.loadtxt('EandR/out/%s_%d_linked.dat' % (t, n))\n",
    "        temp_t = np.loadtxt('EandR/out/%s_%d_linked_time.dat' % (t, n))\n",
    "        \n",
    "        f.write('%d,%s,%d,%d,%d,%d,%lf,' % (n, 'EandR_linked', T0_VALS[t], T_VALS[t], ns, dt, temp_t))\n",
    "        f.write(','.join(['%lf' % s for s in temp_s]))\n",
    "        f.write('\\n')\n",
    "        \n",
    "        temp_s = np.loadtxt('EandR/out/%s_%d_independent.dat' % (t, n))\n",
    "        temp_t = np.loadtxt('EandR/out/%s_%d_independent_time.dat' % (t, n))\n",
    "        \n",
    "        f.write('%d,%s,%d,%d,%d,%d,%lf,' % (n, 'EandR_independent', T0_VALS[t], T_VALS[t], ns, dt, temp_t))\n",
    "        f.write(','.join(['%lf' % s for s in temp_s]))\n",
    "        f.write('\\n')\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    df              = pd.read_csv('EandR/out/%s_collected.csv' % (t), memory_map=True)\n",
    "    df['AUROC_ben'] = pd.Series(data=[roc_auc_score(true_ben, np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "    df['AUROC_del'] = pd.Series(data=[roc_auc_score(true_del,-np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "    for i in range(L_VALS[t]):\n",
    "        if   true_ben[i]: df['ds%d' % i] = df['s%d' % i] - SB_VALS[t]\n",
    "        elif true_del[i]: df['ds%d' % i] = df['s%d' % i] - SD_VALS[t]\n",
    "        elif true_neu[i]: df['ds%d' % i] = df['s%d' % i]\n",
    "            \n",
    "    df.to_csv('data/EandR_%s_collected_extended.csv.gz' % (t), compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
